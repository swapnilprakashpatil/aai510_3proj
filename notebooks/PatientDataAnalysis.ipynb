{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efbe4892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy>=1.20.0 in d:\\personal\\ai-admissions\\semester 3\\aai-510 - machine learning fundamentals and applications\\final team project\\aai510_3proj\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 1)) (2.2.6)\n",
      "Requirement already satisfied: pandas>=1.3.0 in d:\\personal\\ai-admissions\\semester 3\\aai-510 - machine learning fundamentals and applications\\final team project\\aai510_3proj\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 2)) (2.3.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in d:\\personal\\ai-admissions\\semester 3\\aai-510 - machine learning fundamentals and applications\\final team project\\aai510_3proj\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 3)) (1.6.1)\n",
      "Requirement already satisfied: xgboost>=1.5.0 in d:\\personal\\ai-admissions\\semester 3\\aai-510 - machine learning fundamentals and applications\\final team project\\aai510_3proj\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 4)) (3.0.2)\n",
      "Requirement already satisfied: matplotlib>=3.4.0 in d:\\personal\\ai-admissions\\semester 3\\aai-510 - machine learning fundamentals and applications\\final team project\\aai510_3proj\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 5)) (3.10.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in d:\\personal\\ai-admissions\\semester 3\\aai-510 - machine learning fundamentals and applications\\final team project\\aai510_3proj\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 6)) (0.13.2)\n",
      "Requirement already satisfied: plotly>=5.0.0 in d:\\personal\\ai-admissions\\semester 3\\aai-510 - machine learning fundamentals and applications\\final team project\\aai510_3proj\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 7)) (6.1.2)\n",
      "Requirement already satisfied: nltk>=3.6.0 in d:\\personal\\ai-admissions\\semester 3\\aai-510 - machine learning fundamentals and applications\\final team project\\aai510_3proj\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 8)) (3.9.1)\n",
      "Requirement already satisfied: transformers>=4.20.0 in d:\\personal\\ai-admissions\\semester 3\\aai-510 - machine learning fundamentals and applications\\final team project\\aai510_3proj\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 9)) (4.52.4)\n",
      "Requirement already satisfied: torch>=1.10.0 in d:\\personal\\ai-admissions\\semester 3\\aai-510 - machine learning fundamentals and applications\\final team project\\aai510_3proj\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 10)) (2.7.1)\n",
      "Requirement already satisfied: streamlit>=1.10.0 in d:\\personal\\ai-admissions\\semester 3\\aai-510 - machine learning fundamentals and applications\\final team project\\aai510_3proj\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 11)) (1.45.1)\n",
      "Requirement already satisfied: pytest>=6.0.0 in d:\\personal\\ai-admissions\\semester 3\\aai-510 - machine learning fundamentals and applications\\final team project\\aai510_3proj\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 12)) (8.4.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in d:\\personal\\ai-admissions\\semester 3\\aai-510 - machine learning fundamentals and applications\\final team project\\aai510_3proj\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 13)) (1.5.1)\n",
      "Requirement already satisfied: imbalanced-learn>=0.8.0 in d:\\personal\\ai-admissions\\semester 3\\aai-510 - machine learning fundamentals and applications\\final team project\\aai510_3proj\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 14)) (0.13.0)\n",
      "Requirement already satisfied: wordcloud>=1.8.0 in d:\\personal\\ai-admissions\\semester 3\\aai-510 - machine learning fundamentals and applications\\final team project\\aai510_3proj\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 15)) (1.9.4)\n",
      "Requirement already satisfied: tqdm>=4.60.0 in d:\\personal\\ai-admissions\\semester 3\\aai-510 - machine learning fundamentals and applications\\final team project\\aai510_3proj\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 16)) (4.67.1)\n",
      "Requirement already satisfied: sentencepiece>=0.1.96 in d:\\personal\\ai-admissions\\semester 3\\aai-510 - machine learning fundamentals and applications\\final team project\\aai510_3proj\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 17)) (0.2.0)\n",
      "Requirement already satisfied: accelerate>=0.12.0 in d:\\personal\\ai-admissions\\semester 3\\aai-510 - machine learning fundamentals and applications\\final team project\\aai510_3proj\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 18)) (1.7.0)\n",
      "Requirement already satisfied: evaluate>=0.3.0 in d:\\personal\\ai-admissions\\semester 3\\aai-510 - machine learning fundamentals and applications\\final team project\\aai510_3proj\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 19)) (0.4.3)\n",
      "Requirement already satisfied: beautifulsoup4>=4.9.0 in d:\\personal\\ai-admissions\\semester 3\\aai-510 - machine learning fundamentals and applications\\final team project\\aai510_3proj\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 20)) (4.13.4)\n",
      "Requirement already satisfied: regex>=2022.0.0 in d:\\personal\\ai-admissions\\semester 3\\aai-510 - machine learning fundamentals and applications\\final team project\\aai510_3proj\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 21)) (2024.11.6)\n",
      "Requirement already satisfied: scipy>=1.7.0 in d:\\personal\\ai-admissions\\semester 3\\aai-510 - machine learning fundamentals and applications\\final team project\\aai510_3proj\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 22)) (1.15.3)\n",
      "Requirement already satisfied: pytest-cov>=2.12.0 in d:\\personal\\ai-admissions\\semester 3\\aai-510 - machine learning fundamentals and applications\\final team project\\aai510_3proj\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 23)) (6.2.1)\n",
      "Requirement already satisfied: jupyter>=1.0.0 in d:\\personal\\ai-admissions\\semester 3\\aai-510 - machine learning fundamentals and applications\\final team project\\aai510_3proj\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 24)) (1.1.1)\n",
      "Requirement already satisfied: ipywidgets>=7.6.0 in d:\\personal\\ai-admissions\\semester 3\\aai-510 - machine learning fundamentals and applications\\final team project\\aai510_3proj\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 25)) (8.1.7)\n",
      "Requirement already satisfied: notebook>=6.4.0 in d:\\personal\\ai-admissions\\semester 3\\aai-510 - machine learning fundamentals and applications\\final team project\\aai510_3proj\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 26)) (7.4.3)\n",
      "Requirement already satisfied: openpyxl>=3.0.0 in d:\\personal\\ai-admissions\\semester 3\\aai-510 - machine learning fundamentals and applications\\final team project\\aai510_3proj\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 27)) (3.1.5)\n",
      "Requirement already satisfied: tabulate>=0.8.0 in d:\\personal\\ai-admissions\\semester 3\\aai-510 - machine learning fundamentals and applications\\final team project\\aai510_3proj\\.venv\\lib\\site-packages (from -r ../requirements.txt (line 28)) (0.9.0)\n",
      "Collecting medspacy>=1.0.0\n",
      "  Using cached medspacy-1.3.1-py3-none-any.whl\n",
      "Collecting spacy>=3.0.0\n",
      "  Using cached spacy-3.8.7-cp310-cp310-win_amd64.whl (14.9 MB)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement en_core_web_sm>=3.0.0 (from versions: none)\n",
      "ERROR: No matching distribution found for en_core_web_sm>=3.0.0\n",
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../requirements.txt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9bd5190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.pardir, 'src')))\n",
    "\n",
    "# Import project-specific internal modules\n",
    "from preprocessor import DataPreprocessor\n",
    "from plots import PlotGenerator\n",
    "from src import config\n",
    "from config import RUN_CONFIGURATION, EMOTION_STATES, NLP_CONFIG, SENTIMENT_MODEL_EXPORT_PATH_RAW, \\\n",
    "    SENTIMENT_MODEL_EXPORT_PATH_OPTIMIZED, EMOTION_VARIATIONS_PATH, NEGATION_PATTERNS_PATH, \\\n",
    "    HYPERPARAMETERS, RANDOM_STATE, PREDICTION_MODEL_EXPORT_PATH, is_step_enabled\n",
    "from src.sentiment_analysis import SentimentAnalysisModel\n",
    "from src.emotion_postprocessor import EmotionPostProcessor\n",
    "from src.clinical_notes_prediction import ClinicalNotesNoShowPredictor\n",
    "\n",
    "# Create an instance of the preprocessing and plotting classes\n",
    "preprocessor = DataPreprocessor(config)\n",
    "plotter = PlotGenerator(style='whitegrid', palette='viridis', figsize=(10, 6))\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38d49bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shape:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(110527, 17)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'columns:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['PatientId', 'AppointmentID', 'Gender', 'ScheduledDay',\n",
       "       'AppointmentDay', 'Age', 'Neighbourhood', 'Scholarship', 'Hypertension',\n",
       "       'Diabetes', 'Alcoholism', 'Handcap', 'SMS_received', 'No-show',\n",
       "       'PatientNotes', 'PatientSentiment', 'NoShowReason'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientId</th>\n",
       "      <th>AppointmentID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>ScheduledDay</th>\n",
       "      <th>AppointmentDay</th>\n",
       "      <th>Age</th>\n",
       "      <th>Neighbourhood</th>\n",
       "      <th>Scholarship</th>\n",
       "      <th>Hypertension</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Alcoholism</th>\n",
       "      <th>Handcap</th>\n",
       "      <th>SMS_received</th>\n",
       "      <th>No-show</th>\n",
       "      <th>PatientNotes</th>\n",
       "      <th>PatientSentiment</th>\n",
       "      <th>NoShowReason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.987250e+13</td>\n",
       "      <td>5642903</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-29T18:38:08Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>62</td>\n",
       "      <td>JARDIM DA PENHA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Patient with hypertension is receiving care co...</td>\n",
       "      <td>Patient is optimistic and shows no significant...</td>\n",
       "      <td>The patient is focused on improving overall qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.589978e+14</td>\n",
       "      <td>5642503</td>\n",
       "      <td>M</td>\n",
       "      <td>2016-04-29T16:08:27Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>56</td>\n",
       "      <td>JARDIM DA PENHA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No chronic conditions or significant health co...</td>\n",
       "      <td>Patient is generally positive and engaged in c...</td>\n",
       "      <td>Positive experiences with clinic staff, such a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.262962e+12</td>\n",
       "      <td>5642549</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-29T16:19:04Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>62</td>\n",
       "      <td>MATA DA PRAIA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No chronic conditions or significant health co...</td>\n",
       "      <td>Patient feels hopeful and confident about mana...</td>\n",
       "      <td>The patient demonstrates a strong commitment t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.679512e+11</td>\n",
       "      <td>5642828</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-29T17:29:31Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>8</td>\n",
       "      <td>PONTAL DE CAMBURI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Child accompanied by parent/guardian. Reviewed...</td>\n",
       "      <td>Patient is optimistic and shows no significant...</td>\n",
       "      <td>The patient demonstrates a strong commitment t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.841186e+12</td>\n",
       "      <td>5642494</td>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-29T16:07:23Z</td>\n",
       "      <td>2016-04-29T00:00:00Z</td>\n",
       "      <td>56</td>\n",
       "      <td>JARDIM DA PENHA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Patient with diabetes is receiving cultural co...</td>\n",
       "      <td>Patient is optimistic and shows no significant...</td>\n",
       "      <td>Interest in exploring new treatment options, m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PatientId  AppointmentID Gender          ScheduledDay  \\\n",
       "0  2.987250e+13        5642903      F  2016-04-29T18:38:08Z   \n",
       "1  5.589978e+14        5642503      M  2016-04-29T16:08:27Z   \n",
       "2  4.262962e+12        5642549      F  2016-04-29T16:19:04Z   \n",
       "3  8.679512e+11        5642828      F  2016-04-29T17:29:31Z   \n",
       "4  8.841186e+12        5642494      F  2016-04-29T16:07:23Z   \n",
       "\n",
       "         AppointmentDay  Age      Neighbourhood  Scholarship  Hypertension  \\\n",
       "0  2016-04-29T00:00:00Z   62    JARDIM DA PENHA            0             1   \n",
       "1  2016-04-29T00:00:00Z   56    JARDIM DA PENHA            0             0   \n",
       "2  2016-04-29T00:00:00Z   62      MATA DA PRAIA            0             0   \n",
       "3  2016-04-29T00:00:00Z    8  PONTAL DE CAMBURI            0             0   \n",
       "4  2016-04-29T00:00:00Z   56    JARDIM DA PENHA            0             1   \n",
       "\n",
       "   Diabetes  Alcoholism  Handcap  SMS_received No-show  \\\n",
       "0         0           0        0             0      No   \n",
       "1         0           0        0             0      No   \n",
       "2         0           0        0             0      No   \n",
       "3         0           0        0             0      No   \n",
       "4         1           0        0             0      No   \n",
       "\n",
       "                                        PatientNotes  \\\n",
       "0  Patient with hypertension is receiving care co...   \n",
       "1  No chronic conditions or significant health co...   \n",
       "2  No chronic conditions or significant health co...   \n",
       "3  Child accompanied by parent/guardian. Reviewed...   \n",
       "4  Patient with diabetes is receiving cultural co...   \n",
       "\n",
       "                                    PatientSentiment  \\\n",
       "0  Patient is optimistic and shows no significant...   \n",
       "1  Patient is generally positive and engaged in c...   \n",
       "2  Patient feels hopeful and confident about mana...   \n",
       "3  Patient is optimistic and shows no significant...   \n",
       "4  Patient is optimistic and shows no significant...   \n",
       "\n",
       "                                        NoShowReason  \n",
       "0  The patient is focused on improving overall qu...  \n",
       "1  Positive experiences with clinic staff, such a...  \n",
       "2  The patient demonstrates a strong commitment t...  \n",
       "3  The patient demonstrates a strong commitment t...  \n",
       "4  Interest in exploring new treatment options, m...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientId</th>\n",
       "      <th>AppointmentID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Scholarship</th>\n",
       "      <th>Hypertension</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Alcoholism</th>\n",
       "      <th>Handcap</th>\n",
       "      <th>SMS_received</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.105270e+05</td>\n",
       "      <td>1.105270e+05</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.474963e+14</td>\n",
       "      <td>5.675305e+06</td>\n",
       "      <td>37.088874</td>\n",
       "      <td>0.098266</td>\n",
       "      <td>0.197246</td>\n",
       "      <td>0.071865</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>0.022248</td>\n",
       "      <td>0.321026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.560949e+14</td>\n",
       "      <td>7.129575e+04</td>\n",
       "      <td>23.110205</td>\n",
       "      <td>0.297675</td>\n",
       "      <td>0.397921</td>\n",
       "      <td>0.258265</td>\n",
       "      <td>0.171686</td>\n",
       "      <td>0.161543</td>\n",
       "      <td>0.466873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.921784e+04</td>\n",
       "      <td>5.030230e+06</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.172614e+12</td>\n",
       "      <td>5.640286e+06</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.173184e+13</td>\n",
       "      <td>5.680573e+06</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.439172e+13</td>\n",
       "      <td>5.725524e+06</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.999816e+14</td>\n",
       "      <td>5.790484e+06</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          PatientId  AppointmentID            Age    Scholarship  \\\n",
       "count  1.105270e+05   1.105270e+05  110527.000000  110527.000000   \n",
       "mean   1.474963e+14   5.675305e+06      37.088874       0.098266   \n",
       "std    2.560949e+14   7.129575e+04      23.110205       0.297675   \n",
       "min    3.921784e+04   5.030230e+06      -1.000000       0.000000   \n",
       "25%    4.172614e+12   5.640286e+06      18.000000       0.000000   \n",
       "50%    3.173184e+13   5.680573e+06      37.000000       0.000000   \n",
       "75%    9.439172e+13   5.725524e+06      55.000000       0.000000   \n",
       "max    9.999816e+14   5.790484e+06     115.000000       1.000000   \n",
       "\n",
       "        Hypertension       Diabetes     Alcoholism        Handcap  \\\n",
       "count  110527.000000  110527.000000  110527.000000  110527.000000   \n",
       "mean        0.197246       0.071865       0.030400       0.022248   \n",
       "std         0.397921       0.258265       0.171686       0.161543   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       4.000000   \n",
       "\n",
       "        SMS_received  \n",
       "count  110527.000000  \n",
       "mean        0.321026  \n",
       "std         0.466873  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         1.000000  \n",
       "max         1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if is_step_enabled('dataload'):\n",
    "    df = preprocessor.load_data(config.DATASET_PATH)\n",
    "    display(\"shape:\", df.shape)\n",
    "    display(\"columns:\", df.columns)\n",
    "    display(df.head())\n",
    "    display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ec00c0",
   "metadata": {},
   "source": [
    "# Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a8282c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[preprocessing] Starting preprocessing...\n",
      "Initial shape of the dataset: (110527, 17)\n",
      "Initial columns in the dataset: Index(['PatientId', 'AppointmentID', 'Gender', 'ScheduledDay',\n",
      "       'AppointmentDay', 'Age', 'Neighbourhood', 'Scholarship', 'Hypertension',\n",
      "       'Diabetes', 'Alcoholism', 'Handcap', 'SMS_received', 'No-show',\n",
      "       'PatientNotes', 'PatientSentiment', 'NoShowReason'],\n",
      "      dtype='object')\n",
      "Dropping unnecessary columns...\n",
      "Remaining columns: Index(['Gender', 'ScheduledDay', 'AppointmentDay', 'Age', 'Neighbourhood',\n",
      "       'Scholarship', 'Hypertension', 'Diabetes', 'Alcoholism', 'Handcap',\n",
      "       'SMS_received', 'No-show', 'PatientNotes', 'PatientSentiment',\n",
      "       'NoShowReason'],\n",
      "      dtype='object')\n",
      "Converting date columns to datetime...\n",
      "Handling missing values...\n",
      "Adding emotional state columns...\n",
      "Emotional state columns added: ['anxiety', 'stress', 'confusion', 'hopeful', 'fear']\n",
      "Final shape of the dataset: (110527, 21)\n",
      "Final columns in the dataset: Index(['Gender', 'ScheduledDay', 'AppointmentDay', 'Age', 'Neighbourhood',\n",
      "       'Scholarship', 'Hypertension', 'Diabetes', 'Alcoholism', 'Handcap',\n",
      "       'SMS_received', 'No-show', 'PatientNotes', 'PatientSentiment',\n",
      "       'NoShowReason', 'WaitDays', 'anxiety', 'stress', 'confusion', 'hopeful',\n",
      "       'fear'],\n",
      "      dtype='object')\n",
      "[preprocessing] Preprocessing complete.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'shape:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(110527, 21)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'columns:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['Gender', 'ScheduledDay', 'AppointmentDay', 'Age', 'Neighbourhood',\n",
       "       'Scholarship', 'Hypertension', 'Diabetes', 'Alcoholism', 'Handcap',\n",
       "       'SMS_received', 'No-show', 'PatientNotes', 'PatientSentiment',\n",
       "       'NoShowReason', 'WaitDays', 'anxiety', 'stress', 'confusion', 'hopeful',\n",
       "       'fear'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>ScheduledDay</th>\n",
       "      <th>AppointmentDay</th>\n",
       "      <th>Age</th>\n",
       "      <th>Neighbourhood</th>\n",
       "      <th>Scholarship</th>\n",
       "      <th>Hypertension</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Alcoholism</th>\n",
       "      <th>Handcap</th>\n",
       "      <th>...</th>\n",
       "      <th>No-show</th>\n",
       "      <th>PatientNotes</th>\n",
       "      <th>PatientSentiment</th>\n",
       "      <th>NoShowReason</th>\n",
       "      <th>WaitDays</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>stress</th>\n",
       "      <th>confusion</th>\n",
       "      <th>hopeful</th>\n",
       "      <th>fear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-29 18:38:08+00:00</td>\n",
       "      <td>2016-04-29 00:00:00+00:00</td>\n",
       "      <td>62.0</td>\n",
       "      <td>JARDIM DA PENHA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Patient with hypertension is receiving care co...</td>\n",
       "      <td>Patient is optimistic and shows no significant...</td>\n",
       "      <td>The patient is focused on improving overall qu...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-04-29 16:08:27+00:00</td>\n",
       "      <td>2016-04-29 00:00:00+00:00</td>\n",
       "      <td>56.0</td>\n",
       "      <td>JARDIM DA PENHA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>No chronic conditions or significant health co...</td>\n",
       "      <td>Patient is generally positive and engaged in c...</td>\n",
       "      <td>Positive experiences with clinic staff, such a...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-29 16:19:04+00:00</td>\n",
       "      <td>2016-04-29 00:00:00+00:00</td>\n",
       "      <td>62.0</td>\n",
       "      <td>MATA DA PRAIA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>No chronic conditions or significant health co...</td>\n",
       "      <td>Patient feels hopeful and confident about mana...</td>\n",
       "      <td>The patient demonstrates a strong commitment t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-29 17:29:31+00:00</td>\n",
       "      <td>2016-04-29 00:00:00+00:00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>PONTAL DE CAMBURI</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Child accompanied by parent/guardian. Reviewed...</td>\n",
       "      <td>Patient is optimistic and shows no significant...</td>\n",
       "      <td>The patient demonstrates a strong commitment t...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-04-29 16:07:23+00:00</td>\n",
       "      <td>2016-04-29 00:00:00+00:00</td>\n",
       "      <td>56.0</td>\n",
       "      <td>JARDIM DA PENHA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Patient with diabetes is receiving cultural co...</td>\n",
       "      <td>Patient is optimistic and shows no significant...</td>\n",
       "      <td>Interest in exploring new treatment options, m...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender              ScheduledDay            AppointmentDay   Age  \\\n",
       "0       0 2016-04-29 18:38:08+00:00 2016-04-29 00:00:00+00:00  62.0   \n",
       "1       1 2016-04-29 16:08:27+00:00 2016-04-29 00:00:00+00:00  56.0   \n",
       "2       0 2016-04-29 16:19:04+00:00 2016-04-29 00:00:00+00:00  62.0   \n",
       "3       0 2016-04-29 17:29:31+00:00 2016-04-29 00:00:00+00:00   8.0   \n",
       "4       0 2016-04-29 16:07:23+00:00 2016-04-29 00:00:00+00:00  56.0   \n",
       "\n",
       "       Neighbourhood  Scholarship  Hypertension  Diabetes  Alcoholism  \\\n",
       "0    JARDIM DA PENHA            0             1         0           0   \n",
       "1    JARDIM DA PENHA            0             0         0           0   \n",
       "2      MATA DA PRAIA            0             0         0           0   \n",
       "3  PONTAL DE CAMBURI            0             0         0           0   \n",
       "4    JARDIM DA PENHA            0             1         1           0   \n",
       "\n",
       "   Handcap  ...  No-show                                       PatientNotes  \\\n",
       "0        0  ...        0  Patient with hypertension is receiving care co...   \n",
       "1        0  ...        0  No chronic conditions or significant health co...   \n",
       "2        0  ...        0  No chronic conditions or significant health co...   \n",
       "3        0  ...        0  Child accompanied by parent/guardian. Reviewed...   \n",
       "4        0  ...        0  Patient with diabetes is receiving cultural co...   \n",
       "\n",
       "                                    PatientSentiment  \\\n",
       "0  Patient is optimistic and shows no significant...   \n",
       "1  Patient is generally positive and engaged in c...   \n",
       "2  Patient feels hopeful and confident about mana...   \n",
       "3  Patient is optimistic and shows no significant...   \n",
       "4  Patient is optimistic and shows no significant...   \n",
       "\n",
       "                                        NoShowReason WaitDays  anxiety  \\\n",
       "0  The patient is focused on improving overall qu...       -1        1   \n",
       "1  Positive experiences with clinic staff, such a...       -1        1   \n",
       "2  The patient demonstrates a strong commitment t...       -1        1   \n",
       "3  The patient demonstrates a strong commitment t...       -1        1   \n",
       "4  Interest in exploring new treatment options, m...       -1        1   \n",
       "\n",
       "   stress  confusion  hopeful  fear  \n",
       "0       1          0        1     1  \n",
       "1       1          0        0     1  \n",
       "2       1          0        1     1  \n",
       "3       1          0        0     1  \n",
       "4       1          0        1     1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Scholarship</th>\n",
       "      <th>Hypertension</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Alcoholism</th>\n",
       "      <th>Handcap</th>\n",
       "      <th>SMS_received</th>\n",
       "      <th>No-show</th>\n",
       "      <th>WaitDays</th>\n",
       "      <th>anxiety</th>\n",
       "      <th>stress</th>\n",
       "      <th>confusion</th>\n",
       "      <th>hopeful</th>\n",
       "      <th>fear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.0</td>\n",
       "      <td>110527.0</td>\n",
       "      <td>110527.000000</td>\n",
       "      <td>110527.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.350023</td>\n",
       "      <td>37.088874</td>\n",
       "      <td>0.098266</td>\n",
       "      <td>0.197246</td>\n",
       "      <td>0.071865</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>0.022248</td>\n",
       "      <td>0.321026</td>\n",
       "      <td>0.201933</td>\n",
       "      <td>9.183702</td>\n",
       "      <td>0.669538</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.665186</td>\n",
       "      <td>0.669538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.476979</td>\n",
       "      <td>23.110205</td>\n",
       "      <td>0.297675</td>\n",
       "      <td>0.397921</td>\n",
       "      <td>0.258265</td>\n",
       "      <td>0.171686</td>\n",
       "      <td>0.161543</td>\n",
       "      <td>0.466873</td>\n",
       "      <td>0.401444</td>\n",
       "      <td>15.254996</td>\n",
       "      <td>0.470382</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.471928</td>\n",
       "      <td>0.470382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Gender            Age    Scholarship   Hypertension  \\\n",
       "count  110527.000000  110527.000000  110527.000000  110527.000000   \n",
       "mean        0.350023      37.088874       0.098266       0.197246   \n",
       "std         0.476979      23.110205       0.297675       0.397921   \n",
       "min         0.000000      -1.000000       0.000000       0.000000   \n",
       "25%         0.000000      18.000000       0.000000       0.000000   \n",
       "50%         0.000000      37.000000       0.000000       0.000000   \n",
       "75%         1.000000      55.000000       0.000000       0.000000   \n",
       "max         1.000000     115.000000       1.000000       1.000000   \n",
       "\n",
       "            Diabetes     Alcoholism        Handcap   SMS_received  \\\n",
       "count  110527.000000  110527.000000  110527.000000  110527.000000   \n",
       "mean        0.071865       0.030400       0.022248       0.321026   \n",
       "std         0.258265       0.171686       0.161543       0.466873   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       1.000000   \n",
       "max         1.000000       1.000000       4.000000       1.000000   \n",
       "\n",
       "             No-show       WaitDays        anxiety    stress  confusion  \\\n",
       "count  110527.000000  110527.000000  110527.000000  110527.0   110527.0   \n",
       "mean        0.201933       9.183702       0.669538       1.0        0.0   \n",
       "std         0.401444      15.254996       0.470382       0.0        0.0   \n",
       "min         0.000000      -7.000000       0.000000       1.0        0.0   \n",
       "25%         0.000000      -1.000000       0.000000       1.0        0.0   \n",
       "50%         0.000000       3.000000       1.000000       1.0        0.0   \n",
       "75%         0.000000      14.000000       1.000000       1.0        0.0   \n",
       "max         1.000000     178.000000       1.000000       1.0        0.0   \n",
       "\n",
       "             hopeful           fear  \n",
       "count  110527.000000  110527.000000  \n",
       "mean        0.665186       0.669538  \n",
       "std         0.471928       0.470382  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         1.000000       1.000000  \n",
       "75%         1.000000       1.000000  \n",
       "max         1.000000       1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if is_step_enabled('data_preprocess'):\n",
    "    df = preprocessor.preprocess_data(df)\n",
    "    display(\"shape:\", df.shape)\n",
    "    display(\"columns:\", df.columns)\n",
    "    display(df.head())\n",
    "    display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d02a85",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "In this section, we perform exploratory data analysis on the patient appointments dataset to understand the data, visualize key features, and derive insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b43c06",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "\n",
    "Visualize the distribution of key features and their relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc163799",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_step_enabled('eda'):\n",
    "    # Distribution of Age - Using class-based approach\n",
    "    plotter.plot_histplot(\n",
    "        data=df,\n",
    "        column='Age',\n",
    "        bins=30,\n",
    "        kde=True,\n",
    "        title='Age Distribution',\n",
    "        xlabel='Age',\n",
    "        ylabel='Frequency',\n",
    "        figsize=(10, 6)\n",
    "    )\n",
    "\n",
    "    # Countplot of No-show vs Show\n",
    "    plotter.plot_countplot(\n",
    "        data=df,\n",
    "        column='No-show',\n",
    "        title='Count of No-show vs Show',\n",
    "        xlabel='No-show',\n",
    "        ylabel='Count',\n",
    "        figsize=(8, 5)\n",
    "    )\n",
    "\n",
    "    # Correlation heatmap \n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    correlation_matrix = numeric_df.corr()\n",
    "    plotter.plot_heatmap(\n",
    "        data=correlation_matrix,\n",
    "        title='Correlation Heatmap',\n",
    "        fmt='.2f',\n",
    "        cmap='coolwarm',\n",
    "        square=True,\n",
    "        figsize=(12, 8)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c019e2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_step_enabled('eda'):\n",
    "    # Plot emotional states as a bar plot - Using class method\n",
    "    plotter.plot_emotional_states_bar(df)\n",
    "\n",
    "    # Plot word clouds for PatientSentiment, PatientNotes, and NoShowReason\n",
    "    plotter.plot_text_wordcloud(df['PatientSentiment'], title='Patient Sentiment Word Cloud')\n",
    "    plotter.plot_text_wordcloud(df['PatientNotes'], title='Patient Notes Word Cloud')\n",
    "    plotter.plot_text_wordcloud(df['NoShowReason'], title='No-Show Reason Word Cloud')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144f614f",
   "metadata": {},
   "source": [
    "# Supervised Learning for Patient Show/No Show Prediction\n",
    "\n",
    "Implement supervised learning algorithms to predict patient show/no-show."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97278d5",
   "metadata": {},
   "source": [
    "# Unsupervised Learning\n",
    "\n",
    "Apply unsupervised learning techniques to cluster patients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e952d3",
   "metadata": {},
   "source": [
    "## Unsupervised Learning Conclusion\n",
    "\n",
    "K-Means and GMM clustering provided insights into patient groupings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df9fb88",
   "metadata": {},
   "source": [
    "# NLP Analysis on Patient Appointments\n",
    "\n",
    "Perform NLP analysis on patient notes and sentiments.\n",
    "\n",
    "1. Patient Sentiment Analysis - TinyBert\n",
    "1. Patient Notes Analysis -  ClinicalBERT\n",
    "1. No Show Reason Analysis - DistillBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c4443f",
   "metadata": {},
   "source": [
    "# Patient Sentiment Analysis (TinyBERT)\n",
    "\n",
    "This section analyzes patient sentiments using a TinyBERT-based transformer model, with emotion and negation handling. The approach is optimized for CPU and reuses project configuration and CSVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7e90da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_step_enabled('nlp_sentiment_analysis'):\n",
    "    # Instantiate the sentiment analysis model\n",
    "    sa_df = df[['PatientSentiment', 'No-show']].dropna()\n",
    "    sa_model = SentimentAnalysisModel(sa_df, emotional_states=EMOTION_STATES, device=NLP_CONFIG['device'])\n",
    "\n",
    "    # Train the model\n",
    "    sa_model.train()\n",
    "\n",
    "    # Evaluate the model\n",
    "    predictions, actual_labels = sa_model.evaluate()\n",
    "\n",
    "    # Get metrics\n",
    "    sentiment_analysis_metrics = sa_model.report(predictions, actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "689cb840",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_step_enabled('nlp_sentiment_analysis'):\n",
    "    # Print metrics in a readable format\n",
    "    plotter.print_sentiment_metrics(sentiment_analysis_metrics)\n",
    "\n",
    "    # Plot accuracy by emotion with overall accuracy line\n",
    "    plotter.plot_accuracy_by_emotion(sentiment_analysis_metrics)\n",
    "\n",
    "    # Plot confusion matrices for each emotion\n",
    "    plotter.plot_confusion_matrices(actual_labels, predictions, sa_model.emotional_states)\n",
    "\n",
    "    # Plot training and validation loss\n",
    "    sa_stats = sa_model.get_training_stats()\n",
    "    plotter.plot_training_validation_loss(sa_stats['training_losses'], sa_stats['validation_losses'])\n",
    "\n",
    "    # Plot time taken per epoch\n",
    "    plotter.plot_epoch_times(sa_stats['epoch_times'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08d7447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_step_enabled('nlp_sentiment_analysis'):\n",
    "    # Prepare data splits for hyperparameter tuning\n",
    "    X = df['PatientSentiment'].values\n",
    "    y = df[EMOTION_STATES].values\n",
    "\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=NLP_CONFIG['epochs'])\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.15, random_state=NLP_CONFIG['epochs'])\n",
    "\n",
    "    # Run hyperparameter tuning using the class method\n",
    "    results = SentimentAnalysisModel.run_hyperparameter_tuning(\n",
    "        X_train, y_train, X_val, y_val, X_test, y_test,\n",
    "        emotional_states=EMOTION_STATES,\n",
    "        device=NLP_CONFIG['device'],\n",
    "        tokenizer=sa_model.tokenizer,\n",
    "        max_seq_length=NLP_CONFIG['max_length']\n",
    "    )\n",
    "\n",
    "    # Print and plot metrics for each configuration\n",
    "    for i, res in enumerate(results):\n",
    "        print(f\"\\n--- Results for Hyperparameter Configuration {i+1} ---\")\n",
    "        # Compute metrics for each configuration\n",
    "        emotion_accuracies = {emo: accuracy_score(res['actual_labels'][:, idx], res['predictions'][:, idx]) for idx, emo in enumerate(EMOTION_STATES)}\n",
    "        sentiment_analysis_metrics = {\n",
    "            'emotion_accuracies': emotion_accuracies,\n",
    "            'overall_accuracy': res['accuracy'],\n",
    "            'classification_reports': {}  # Optionally fill with classification_report if needed\n",
    "        }\n",
    "        plotter.print_sentiment_metrics(sentiment_analysis_metrics)\n",
    "        plotter.plot_accuracy_by_emotion(sentiment_analysis_metrics)\n",
    "        plotter.plot_confusion_matrices(res['actual_labels'], res['predictions'], EMOTION_STATES)\n",
    "        plotter.plot_training_validation_loss(res['train_losses'], res['val_losses'])\n",
    "        plotter.plot_epoch_times(res['epoch_times'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14306a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_step_enabled('nlp_sentiment_analysis'):\n",
    "    # Select the best model based on accuracy and training time using the class method\n",
    "    best_model, best_params, best_idx, combined_scores = SentimentAnalysisModel.get_best_model_from_results(results)\n",
    "\n",
    "    print(f\"\\nBest model configuration (balanced for both accuracy and speed):\")\n",
    "    print(f\"Learning Rate: {best_params['learning_rate']}\")\n",
    "    print(f\"Batch Size: {best_params['batch_size']}\")\n",
    "    print(f\"Epochs: {best_params['epochs']}\")\n",
    "    print(f\"Accuracy: {results[best_idx]['accuracy']:.4f}\")\n",
    "    print(f\"Training Time: {results[best_idx].get('training_time', sum(results[best_idx]['epoch_times'])):.2f} seconds\")\n",
    "    print(f\"Combined Score: {combined_scores[best_idx]:.4f}\")\n",
    "\n",
    "    # Plot ROC and AUC for each emotion using the class-based plotter\n",
    "    plotter.plot_roc_auc_by_emotion(actual_labels, predictions, EMOTION_STATES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcbf4eb",
   "metadata": {},
   "source": [
    "# Run Sentiment Model Unit Tests\n",
    "\n",
    "Validate the sentiment model's predictions on example texts using the provided unit test. This ensures the model is working as expected and all expected emotions are being detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e258f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_step_enabled('nlp_sentiment_analysis'):\n",
    "    # Export the best model and tokenizer after hyperparameter tuning\n",
    "    SentimentAnalysisModel.export_best_model(\n",
    "        best_model,\n",
    "        sa_model.tokenizer,\n",
    "        SENTIMENT_MODEL_EXPORT_PATH_RAW\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe3a67fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_step_enabled('nlp_sentiment_analysis'):\n",
    "    example_text = \"Patient (minor) is anxious and fearful about medical procedures, sometimes confused by instructions, and stressed by separation from family.\"\n",
    "    expected = {'anxiety': True, 'stress': True, 'confusion': True, 'hopeful': False, 'fear': True}\n",
    "\n",
    "    raw_pred = SentimentAnalysisModel.predict_emotions_raw(\n",
    "        example_text,\n",
    "        sa_model.model,\n",
    "        sa_model.tokenizer,\n",
    "        NLP_CONFIG['device']\n",
    "    )\n",
    "\n",
    "    print(\"Example text:\")\n",
    "    print(example_text)\n",
    "    print(\"\\nEmotion prediction comparison:\")\n",
    "    for emo in expected:\n",
    "        result = \"âœ…\" if raw_pred[emo] == expected[emo] else \"âŒ\"\n",
    "        print(f\"{emo}: expected={expected[emo]}, predicted={raw_pred[emo]} {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b374f4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_step_enabled('nlp_sentiment_analysis'):\n",
    "    # Run the raw model test\n",
    "    !pytest -s ../tests/test_sentiment_anlaysis.py -k test_sentiment_model_predictions_raw --maxfail=1 --disable-warnings -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47adab1f",
   "metadata": {},
   "source": [
    "# Post-Processing with EmotionPostProcessor and Model Evaluation\n",
    "\n",
    "Use the EmotionPostProcessor and the new SentimentAnalysisModel static methods to predict and evaluate emotions with post-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d61c1731",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_step_enabled('nlp_sentiment_analysis'):\n",
    "    example_text = \"Patient (minor) is anxious and fearful about medical procedures, sometimes confused by instructions, and stressed by separation from family.\"\n",
    "    expected = {'anxiety': True, 'stress': True, 'confusion': True, 'hopeful': False, 'fear': True}\n",
    "\n",
    "    post_processed = SentimentAnalysisModel.predict_emotions(\n",
    "        example_text,\n",
    "        sa_model.model,\n",
    "        sa_model.tokenizer,\n",
    "        NLP_CONFIG['device'],\n",
    "        emotion_variations_path=EMOTION_VARIATIONS_PATH,\n",
    "        negation_patterns_path=NEGATION_PATTERNS_PATH\n",
    "    )\n",
    "    print(\"Post-processed emotion prediction:\", post_processed)\n",
    "    print(\"Example text:\")\n",
    "    print(example_text)\n",
    "    print(\"\\nEmotion prediction comparison:\")\n",
    "    for emo in expected:\n",
    "        result = \"âœ…\" if post_processed[emo] == expected[emo] else \"âŒ\"\n",
    "        print(f\"{emo}: expected={expected[emo]}, predicted={post_processed[emo]} {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d35a534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_step_enabled('nlp_sentiment_analysis'):\n",
    "    # Evaluate the model with post-processing on the test set\n",
    "    results_post = SentimentAnalysisModel.evaluate_model_with_post_processing(\n",
    "        sa_model.model,\n",
    "        sa_model.test_loader,\n",
    "        sa_model.tokenizer,\n",
    "        NLP_CONFIG['device'],\n",
    "        emotion_variations_path=NLP_CONFIG.get('emotion_variations_path', '../data/emotion_variations.csv'),\n",
    "        negation_patterns_path=NLP_CONFIG.get('negation_patterns_path', '../data/negation_patterns.csv')\n",
    "    )\n",
    "    print(\"\\nPost-processing overall accuracy:\", results_post['accuracy'])\n",
    "    print(\"Emotion-wise accuracies:\", results_post['emotion_accuracies'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb98b12",
   "metadata": {},
   "source": [
    "# Rerun Unit Tests for Sentiment Model\n",
    "\n",
    "After post-processing and evaluation, rerun the unit tests to ensure everything is working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed5fcd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_step_enabled('nlp_sentiment_analysis'):\n",
    "    # Export the optimized model and tokenizer with post-processor config\n",
    "    os.makedirs(SENTIMENT_MODEL_EXPORT_PATH_OPTIMIZED, exist_ok=True)\n",
    "    shutil.copy(EMOTION_VARIATIONS_PATH, os.path.join(SENTIMENT_MODEL_EXPORT_PATH_OPTIMIZED, os.path.basename(EMOTION_VARIATIONS_PATH)))\n",
    "    shutil.copy(NEGATION_PATTERNS_PATH, os.path.join(SENTIMENT_MODEL_EXPORT_PATH_OPTIMIZED, os.path.basename(NEGATION_PATTERNS_PATH)))\n",
    "    SentimentAnalysisModel.export_best_model(\n",
    "        best_model,\n",
    "        sa_model.tokenizer,\n",
    "        SENTIMENT_MODEL_EXPORT_PATH_OPTIMIZED\n",
    "    )\n",
    "    print(f\"Optimized model and post-processor config exported to: {SENTIMENT_MODEL_EXPORT_PATH_OPTIMIZED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a95d3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_step_enabled('nlp_sentiment_analysis'):\n",
    "    # Run the optimized model test\n",
    "    !pytest -s ../tests/test_sentiment_anlaysis.py -k test_sentiment_model_predictions_optimized  --maxfail=1 --disable-warnings -q"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
